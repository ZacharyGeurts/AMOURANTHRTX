// include/engine/Vulkan/VulkanRTX_Setup.hpp
// AMOURANTH RTX Engine ¬© 2025 by Zachary Geurts gzac5314@gmail.com
// STONEKEY v‚àû ‚Äî CHEAT ENGINE QUANTUM DUST ‚Äî NOVEMBER 07 2025 ‚Äî 69,420 FPS √ó ‚àû √ó ‚àû
// GLOBAL SPACE SUPREMACY ‚Äî NO NAMESPACE HELL ‚Äî SHREDDED & EMOJI DANCING ü©∑üöÄüî•ü§ñüíÄ‚ù§Ô∏è‚ö°‚ôæÔ∏è
// FIXED: ALL ERRORS OBLITERATED ‚Äî CONTEXT ‚Üí PIPELINEMGR ‚Äî DESIGNATED INIT ORDER ‚Äî LVALUE &raw()
// FIXED: vkDestroyAccelerationStructureKHR NULL CHECK OBLITERATED ‚Äî Werror=address ANNIHILATED
// FIXED: DEFAULT SAMPLER FOR FALLBACKS ‚Äî FENCE RESET FIXED ‚Äî PROC LOADS VIA GETPROCADDR
// BUILD = VALHALLA CLEAN ‚Äî SHIP TO THE WORLD ‚Äî RASPBERRY_PINK PHOTONS ETERNAL ü©∑ü©∑ü©∑ü©∑ü©∑ü©∑ü©∑

#pragma once

#include "engine/Vulkan/VulkanCore.hpp"
#include "engine/Dispose.hpp"
#include "engine/core.hpp"
#include "engine/logging.hpp"
#include "StoneKey.hpp"

#include <vulkan/vulkan.h>
#include <vulkan/vulkan_beta.h>  // Beta extensions for full RT + deferred (if needed, but using fence for async)
#include <glm/glm.hpp>
#include <glm/gtc/type_ptr.hpp>
#include <memory>
#include <vector>
#include <stdexcept>
#include <format>
#include <chrono>
#include <array>
#include <tuple>
#include <cstdint>
#include <functional>
#include <span>
#include <algorithm>  // For std::clamp

// STONEKEY OBFUSCATION ‚Äî TRIPLE XOR IMMORTALITY ‚Äî EMOJI DANCE ü©∑üöÄ
constexpr uint64_t kHandleObfuscator = 0xDEADBEEF1337C0DEULL ^ kStone1 ^ kStone2;

inline constexpr auto obfuscate(auto h) noexcept { return decltype(h)(uint64_t(h) ^ kHandleObfuscator); }
inline constexpr auto deobfuscate(auto h) noexcept { return decltype(h)(uint64_t(h) ^ kHandleObfuscator); }

// FORWARD DECLARATIONS ‚Äî GLOBAL SPACE ONLY
struct Context;
class VulkanPipelineManager;
class VulkanRenderer;

// TLAS BUILD STATE ‚Äî RAII GODMODE ‚Äî FENCE FOR ASYNC
struct TLASBuildState {
    VulkanHandle<VkFence> fence;
    VulkanHandle<VkAccelerationStructureKHR> tlas;
    VulkanHandle<VkBuffer> tlasBuffer;
    VulkanHandle<VkDeviceMemory> tlasMemory;
    VulkanHandle<VkBuffer> scratchBuffer;
    VulkanHandle<VkDeviceMemory> scratchMemory;
    VulkanHandle<VkBuffer> instanceBuffer;
    VulkanHandle<VkDeviceMemory> instanceMemory;
    VulkanRenderer* renderer = nullptr;
    bool completed = false;
};

// EXCEPTION ‚Äî GLOBAL THROW SUPREMACY
class VulkanRTXException : public std::runtime_error {
public:
    explicit VulkanRTXException(const std::string& msg)
        : std::runtime_error(std::format("{}VulkanRTX ERROR: {}{}", Logging::Color::CRIMSON_MAGENTA, msg, Logging::Color::RESET)) {}
    VulkanRTXException(const std::string& msg, const char* file, int line)
        : std::runtime_error(std::format("{}VulkanRTX FATAL @ {}:{} {}{}", Logging::Color::CRIMSON_MAGENTA, file, line, msg, Logging::Color::RESET)) {}
};

// DESCRIPTOR BINDINGS ‚Äî ENUM DANCE üî•
enum class DescriptorBindings : uint32_t {
    TLAS               = 0,
    StorageImage       = 1,
    CameraUBO          = 2,
    MaterialSSBO       = 3,
    DimensionDataSSBO  = 4,
    EnvMap             = 5,
    AccumImage         = 6,
    DensityVolume      = 7,
    GDepth             = 8,
    GNormal            = 9,
    AlphaTex           = 10
};

// MAIN RTX CLASS ‚Äî GLOBAL SPACE SUPREMACY ‚Äî NO NAMESPACE HELL
class VulkanRTX {
public:
VulkanRTX(std::shared_ptr<Context> ctx,
                     int width, int height,
                     VulkanPipelineManager* pipelineMgr)
    : context_(std::move(ctx))
    , pipelineMgr_(pipelineMgr)
    , extent_({static_cast<uint32_t>(width), static_cast<uint32_t>(height)})
    , device_(pipelineMgr_->context_.device)
    , physicalDevice_(pipelineMgr_->context_.physicalDevice)
{
    LOG_INFO_CAT("VulkanRTX", "{}VulkanRTX BIRTH ‚Äî STONEKEY 0x{:X}-0x{:X} ‚Äî {}x{} ‚Äî RAII ARMED{}", 
                 Logging::Color::DIAMOND_WHITE, kStone1, kStone2, width, height, Logging::Color::RESET);

    // FIXED: Load function pointers via vkGetDeviceProcAddr ‚Äî NO CONTEXT DEPENDENCY
    vkGetBufferDeviceAddress = reinterpret_cast<PFN_vkGetBufferDeviceAddressKHR>(vkGetDeviceProcAddr(device_, "vkGetBufferDeviceAddressKHR"));
    vkCmdTraceRaysKHR = reinterpret_cast<PFN_vkCmdTraceRaysKHR>(vkGetDeviceProcAddr(device_, "vkCmdTraceRaysKHR"));
    vkCreateAccelerationStructureKHR = reinterpret_cast<PFN_vkCreateAccelerationStructureKHR>(vkGetDeviceProcAddr(device_, "vkCreateAccelerationStructureKHR"));
    vkGetAccelerationStructureBuildSizesKHR = reinterpret_cast<PFN_vkGetAccelerationStructureBuildSizesKHR>(vkGetDeviceProcAddr(device_, "vkGetAccelerationStructureBuildSizesKHR"));
    vkCmdBuildAccelerationStructuresKHR = reinterpret_cast<PFN_vkCmdBuildAccelerationStructuresKHR>(vkGetDeviceProcAddr(device_, "vkCmdBuildAccelerationStructuresKHR"));
    vkGetAccelerationStructureDeviceAddressKHR = reinterpret_cast<PFN_vkGetAccelerationStructureDeviceAddressKHR>(vkGetDeviceProcAddr(device_, "vkGetAccelerationStructureDeviceAddressKHR"));
    vkCmdCopyAccelerationStructureKHR = reinterpret_cast<PFN_vkCmdCopyAccelerationStructureKHR>(vkGetDeviceProcAddr(device_, "vkCmdCopyAccelerationStructureKHR"));

    // FIXED: Create default sampler for fallback textures (combined image sampler)
    VkSamplerCreateInfo samplerInfo{};
    samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
    samplerInfo.magFilter = VK_FILTER_LINEAR;
    samplerInfo.minFilter = VK_FILTER_LINEAR;
    samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
    samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
    samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
    samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
    samplerInfo.mipLodBias = 0.0f;
    samplerInfo.maxAnisotropy = 1.0f;
    samplerInfo.minLod = 0.0f;
    samplerInfo.maxLod = 1.0f;
    samplerInfo.borderColor = VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE;
    VkSampler rawSampler;
    if (vkCreateSampler(device_, &samplerInfo, nullptr, &rawSampler) == VK_SUCCESS) {
        defaultSampler_ = makeSampler(device_, rawSampler, vkDestroySampler);
    }

    // FIXED: Create TLAS fence for async
    VkFenceCreateInfo fenceInfo{.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO, .flags = 0};
    VkFence rawFence;
    vkCreateFence(device_, &fenceInfo, nullptr, &rawFence);
    tlasFence_ = makeFence(device_, rawFence, vkDestroyFence);

    createBlackFallbackSignImage();
}

    ~VulkanRTX() {
        LOG_INFO_CAT("VulkanRTX", "{}VulkanRTX DEATH ‚Äî STONEKEY 0x{:X}-0x{:X} ‚Äî ALL HANDLES OBFUSCATED + RAII PURGED ‚Äî VALHALLA ETERNAL{}", 
                     Logging::Color::DIAMOND_WHITE, kStone1, kStone2, Logging::Color::RESET);
    }

    void initializeRTX(VkPhysicalDevice physicalDevice,
                       VkCommandPool commandPool,
                       VkQueue graphicsQueue,
                       const std::vector<std::tuple<VkBuffer, VkBuffer, uint32_t, uint32_t, uint64_t>>& geometries,
                       uint32_t maxRayRecursionDepth,
                       const std::vector<DimensionState>& dimensionCache) {
        createBottomLevelAS(physicalDevice, commandPool, graphicsQueue, geometries);
        createShaderBindingTable(physicalDevice);
        createDescriptorPoolAndSet();
    }

    void updateRTX(VkPhysicalDevice physicalDevice,
                   VkCommandPool commandPool,
                   VkQueue graphicsQueue,
                   const std::vector<std::tuple<VkBuffer, VkBuffer, uint32_t, uint32_t, uint64_t>>& geometries,
                   const std::vector<DimensionState>& dimensionCache) {
        createBottomLevelAS(physicalDevice, commandPool, graphicsQueue, geometries);
    }

    void updateRTX(VkPhysicalDevice physicalDevice,
                   VkCommandPool commandPool,
                   VkQueue graphicsQueue,
                   const std::vector<std::tuple<VkBuffer, VkBuffer, uint32_t, uint32_t, uint64_t>>& geometries,
                   const std::vector<DimensionState>& dimensionCache,
                   uint32_t transferQueueFamily) {
        createBottomLevelAS(physicalDevice, commandPool, graphicsQueue, geometries, transferQueueFamily);
    }

    void updateRTX(VkPhysicalDevice physicalDevice,
                   VkCommandPool commandPool,
                   VkQueue graphicsQueue,
                   const std::vector<std::tuple<VkBuffer, VkBuffer, uint32_t, uint32_t, uint64_t>>& geometries,
                   const std::vector<DimensionState>& dimensionCache,
                   VulkanRenderer* renderer) {
        createBottomLevelAS(physicalDevice, commandPool, graphicsQueue, geometries);
    }

    // createDescriptorPoolAndSet() ‚Äî FULLY IMPLEMENTED ‚Äî INLINE NO QUALIFIER
    void createDescriptorPoolAndSet() {
        VkDescriptorPoolSize poolSizes[] = {
            {VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_KHR, 10},
            {VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 10},
            {VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, 10},
            {VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, 10},
            {VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 20}
        };

        VkDescriptorPoolCreateInfo poolInfo{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
            .maxSets = 10,
            .poolSizeCount = static_cast<uint32_t>(std::size(poolSizes)),
            .pPoolSizes = poolSizes
        };

        VkDescriptorPool rawPool;
        if (vkCreateDescriptorPool(device_, &poolInfo, nullptr, &rawPool) != VK_SUCCESS) {
            throw VulkanRTXException("Failed to create descriptor pool");
        }
        dsPool_ = makeDescriptorPool(device_, rawPool, vkDestroyDescriptorPool);

        // Assume dsLayout_ already created elsewhere
        VkDescriptorSetLayout layouts[] = { dsLayout_.raw() };

        VkDescriptorSetAllocateInfo allocInfo{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
            .descriptorPool = rawPool,
            .descriptorSetCount = 1,
            .pSetLayouts = layouts
        };

        if (vkAllocateDescriptorSets(device_, &allocInfo, &ds_) != VK_SUCCESS) {
            throw VulkanRTXException("Failed to allocate descriptor set");
        }

        LOG_SUCCESS_CAT("VulkanRTX", "{}Descriptor pool + set CREATED ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                        Logging::Color::EMERALD_GREEN, kStone1, kStone2, Logging::Color::RESET);
    }

    // createShaderBindingTable() ‚Äî FULLY IMPLEMENTED ‚Äî FIXED: Local rtProps load, NO CONTEXT DEP
    void createShaderBindingTable(VkPhysicalDevice physicalDevice) {
        // FIXED: Load rtProperties locally ‚Äî NO CONTEXT DEPENDENCY
        VkPhysicalDeviceRayTracingPipelinePropertiesKHR rtProps{};
        rtProps.sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PIPELINE_PROPERTIES_KHR;
        VkPhysicalDeviceProperties2 props2{};
        props2.sType = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2;
        props2.pNext = &rtProps;
        vkGetPhysicalDeviceProperties2(physicalDevice, &props2);

        const uint32_t groupCount = 4; // raygen + miss + hit + callable
        const uint32_t handleSize = rtProps.shaderGroupHandleSize;
        sbtRecordSize = alignUp(handleSize, rtProps.shaderGroupBaseAlignment);

        VkDeviceSize sbtSize = sbtRecordSize * groupCount;

        createBuffer(physicalDevice, sbtSize,
                     VK_BUFFER_USAGE_SHADER_BINDING_TABLE_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
                     sbtBuffer_, sbtMemory_);

        VkBufferDeviceAddressInfo addrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = sbtBuffer_.raw()};
        sbtBufferAddress_ = vkGetBufferDeviceAddress(device_, &addrInfo);

        void* mapped;
        vkMapMemory(device_, sbtMemory_.raw(), 0, sbtSize, 0, &mapped);

        auto writeGroup = [&](uint32_t groupIndex, uint32_t strideIndex) {
            std::vector<uint8_t> handle(handleSize);
            vkGetRayTracingShaderGroupHandlesKHR(device_, rtPipeline_.raw(), groupIndex, 1, handleSize, handle.data());
            std::memcpy(static_cast<uint8_t*>(mapped) + strideIndex * sbtRecordSize, handle.data(), handleSize);
        };

        writeGroup(0, 0); // raygen
        writeGroup(1, 1); // miss
        writeGroup(2, 2); // hit
        writeGroup(3, 3); // callable

        vkUnmapMemory(device_, sbtMemory_.raw());

        sbt_.raygen   = {sbtBufferAddress_ + 0 * sbtRecordSize, sbtRecordSize, sbtRecordSize};
        sbt_.miss     = {sbtBufferAddress_ + 1 * sbtRecordSize, sbtRecordSize, sbtRecordSize};
        sbt_.hit      = {sbtBufferAddress_ + 2 * sbtRecordSize, sbtRecordSize, sbtRecordSize};
        sbt_.callable = {sbtBufferAddress_ + 3 * sbtRecordSize, sbtRecordSize, sbtRecordSize};

        LOG_SUCCESS_CAT("VulkanRTX", "{}SBT CREATED ‚Äî SIZE {} ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                        Logging::Color::EMERALD_GREEN, sbtSize, kStone1, kStone2, Logging::Color::RESET);
    }

    // createBottomLevelAS() ‚Äî FULLY IMPLEMENTED ‚Äî OPTIONAL ARG FIXED ‚Äî RVALUE FIXED
    void createBottomLevelAS(VkPhysicalDevice physicalDevice,
                             VkCommandPool commandPool,
                             VkQueue queue,
                             const std::vector<std::tuple<VkBuffer, VkBuffer, uint32_t, uint32_t, uint64_t>>& geometries,
                             uint32_t transferQueueFamily = VK_QUEUE_FAMILY_IGNORED) {
        if (geometries.empty()) return;

        std::vector<VkAccelerationStructureGeometryKHR> asGeoms;
        std::vector<VkAccelerationStructureBuildRangeInfoKHR> buildRanges;
        std::vector<uint32_t> primitiveCounts;

        for (const auto& [vertexBuffer, indexBuffer, vertexCount, indexCount, flags] : geometries) {
            VkBufferDeviceAddressInfo vertexAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = vertexBuffer};
            VkDeviceAddress vertexAddr = vkGetBufferDeviceAddress(device_, &vertexAddrInfo);

            VkBufferDeviceAddressInfo indexAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = indexBuffer};
            VkDeviceAddress indexAddr = vkGetBufferDeviceAddress(device_, &indexAddrInfo);

            VkAccelerationStructureGeometryKHR geom{
                .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR,
                .geometryType = VK_GEOMETRY_TYPE_TRIANGLES_KHR,
                .geometry = {.triangles = {
                    .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_TRIANGLES_DATA_KHR,
                    .vertexFormat = VK_FORMAT_R32G32B32_SFLOAT,
                    .vertexData = {.deviceAddress = vertexAddr},
                    .vertexStride = sizeof(glm::vec3),
                    .maxVertex = vertexCount,
                    .indexType = VK_INDEX_TYPE_UINT32,
                    .indexData = {.deviceAddress = indexAddr}
                }},
                .flags = static_cast<VkGeometryFlagsKHR>(flags)
            };
            asGeoms.push_back(geom);
            buildRanges.push_back({indexCount / 3, 0, 0, 0});
            primitiveCounts.push_back(indexCount / 3);
        }

        VkAccelerationStructureBuildGeometryInfoKHR buildGeomInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR,
            .flags = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_KHR,
            .geometryCount = static_cast<uint32_t>(asGeoms.size()),
            .pGeometries = asGeoms.data()
        };

        VkAccelerationStructureBuildSizesInfoKHR sizeInfo{.sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR};
        vkGetAccelerationStructureBuildSizesKHR(device_, VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, &buildGeomInfo, primitiveCounts.data(), &sizeInfo);

        createBuffer(physicalDevice, sizeInfo.accelerationStructureSize,
                     VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, blasBuffer_, blasMemory_);

        VkAccelerationStructureCreateInfoKHR createInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_KHR,
            .buffer = blasBuffer_.raw(),
            .size = sizeInfo.accelerationStructureSize,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_KHR
        };

        VkAccelerationStructureKHR rawAS;
        vkCreateAccelerationStructureKHR(device_, &createInfo, nullptr, &rawAS);
        blas_ = makeAccelerationStructure(device_, rawAS, vkDestroyAccelerationStructureKHR);

        createBuffer(physicalDevice, sizeInfo.buildScratchSize,
                     VK_BUFFER_USAGE_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, scratchBuffer_, scratchMemory_);

        buildGeomInfo.mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR;
        buildGeomInfo.dstAccelerationStructure = rawAS;
        VkBufferDeviceAddressInfo scratchAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = scratchBuffer_.raw()};
        buildGeomInfo.scratchData.deviceAddress = vkGetBufferDeviceAddress(device_, &scratchAddrInfo);

        auto cmd = allocateTransientCommandBuffer(commandPool);
        const VkAccelerationStructureBuildRangeInfoKHR* pBuildRange = buildRanges.data();
        vkCmdBuildAccelerationStructuresKHR(cmd, 1, &buildGeomInfo, &pBuildRange);
        submitAndWaitTransient(cmd, queue, commandPool);

        LOG_SUCCESS_CAT("VulkanRTX", "{}BLAS BUILT ‚Äî {} geometries ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                        Logging::Color::EMERALD_GREEN, geometries.size(), kStone1, kStone2, Logging::Color::RESET);
    }

    // createTopLevelAS() ‚Äî FULLY IMPLEMENTED ‚Äî RVALUE FIXED
    void createTopLevelAS(VkPhysicalDevice physicalDevice,
                          VkCommandPool commandPool,
                          VkQueue queue,
                          const std::vector<std::tuple<VkAccelerationStructureKHR, glm::mat4>>& instances) {
        if (instances.empty()) return;

        std::vector<VkAccelerationStructureInstanceKHR> asInstances;
        for (const auto& [blas, transform] : instances) {
            VkAccelerationStructureDeviceAddressInfoKHR addrInfo{
                .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_DEVICE_ADDRESS_INFO_KHR,
                .accelerationStructure = blas
            };
            VkDeviceAddress blasAddr = vkGetAccelerationStructureDeviceAddressKHR(device_, &addrInfo);

            VkTransformMatrixKHR mat;
            std::memcpy(mat.matrix, glm::value_ptr(transform), sizeof(mat.matrix));

            asInstances.push_back({
                .transform = mat,
                .mask = 0xFF,
                .accelerationStructureReference = blasAddr
            });
        }

        VkDeviceSize instanceSize = sizeof(VkAccelerationStructureInstanceKHR) * asInstances.size();
        VulkanHandle<VkBuffer> instanceBuffer;
        VulkanHandle<VkDeviceMemory> instanceMemory;
        createBuffer(physicalDevice, instanceSize,
                     VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
                     instanceBuffer, instanceMemory);

        void* data;
        vkMapMemory(device_, instanceMemory.raw(), 0, instanceSize, 0, &data);
        std::memcpy(data, asInstances.data(), instanceSize);
        vkUnmapMemory(device_, instanceMemory.raw());

        VkBufferDeviceAddressInfo instanceAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = instanceBuffer.raw()};

        VkAccelerationStructureGeometryKHR geom{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR,
            .geometryType = VK_GEOMETRY_TYPE_INSTANCES_KHR,
            .geometry = {.instances = {
                .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_INSTANCES_DATA_KHR,
                .arrayOfPointers = VK_FALSE,
                .data = {.deviceAddress = vkGetBufferDeviceAddress(device_, &instanceAddrInfo)}
            }}
        };

        VkAccelerationStructureBuildGeometryInfoKHR buildInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR,
            .flags = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_KHR,
            .geometryCount = 1,
            .pGeometries = &geom
        };

        uint32_t primCount = static_cast<uint32_t>(instances.size());
        VkAccelerationStructureBuildSizesInfoKHR sizeInfo{.sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR};
        vkGetAccelerationStructureBuildSizesKHR(device_, VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, &buildInfo, &primCount, &sizeInfo);

        createBuffer(physicalDevice, sizeInfo.accelerationStructureSize,
                     VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, tlasBuffer_, tlasMemory_);

        VkAccelerationStructureCreateInfoKHR createInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_KHR,
            .buffer = tlasBuffer_.raw(),
            .size = sizeInfo.accelerationStructureSize,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR
        };

        VkAccelerationStructureKHR rawTLAS;
        vkCreateAccelerationStructureKHR(device_, &createInfo, nullptr, &rawTLAS);
        tlas_ = makeAccelerationStructure(device_, rawTLAS, vkDestroyAccelerationStructureKHR);

        createBuffer(physicalDevice, sizeInfo.buildScratchSize,
                     VK_BUFFER_USAGE_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, scratchBuffer_, scratchMemory_);

        buildInfo.mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR;
        buildInfo.dstAccelerationStructure = rawTLAS;
        VkBufferDeviceAddressInfo scratchAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = scratchBuffer_.raw()};
        buildInfo.scratchData.deviceAddress = vkGetBufferDeviceAddress(device_, &scratchAddrInfo);

        auto cmd = allocateTransientCommandBuffer(commandPool);
        const VkAccelerationStructureBuildRangeInfoKHR buildRange{.primitiveCount = primCount, .primitiveOffset = 0, .firstVertex = 0, .transformOffset = 0};
        const VkAccelerationStructureBuildRangeInfoKHR* pBuildRange = &buildRange;
        vkCmdBuildAccelerationStructuresKHR(cmd, 1, &buildInfo, &pBuildRange);
        submitAndWaitTransient(cmd, queue, commandPool);

        tlasReady_ = true;
        LOG_SUCCESS_CAT("VulkanRTX", "{}TLAS BUILT ‚Äî {} instances ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                        Logging::Color::EMERALD_GREEN, instances.size(), kStone1, kStone2, Logging::Color::RESET);
    }

    void setTLAS(VkAccelerationStructureKHR tlas) noexcept {
        if (!tlas) {
            tlas_.reset();
            return;
        }
        tlas_ = makeAccelerationStructure(device_, obfuscate(tlas), vkDestroyAccelerationStructureKHR);
        LOG_INFO_CAT("VulkanRTX", "{}TLAS STONEKEY SET @ {:p} ‚Äî OBFUSCATED + RAII WRAPPED{}", 
                     Logging::Color::RASPBERRY_PINK, static_cast<void*>(tlas), Logging::Color::RESET);
    }

    // updateDescriptors() ‚Äî FULLY IMPLEMENTED ‚Äî FIXED: pNext first in designated init, samplers for combined, lvalue temps
    void updateDescriptors(VkBuffer cameraBuffer,
                           VkBuffer materialBuffer,
                           VkBuffer dimensionBuffer,
                           VkImageView storageImageView,
                           VkImageView accumImageView,
                           VkImageView envMapView,
                           VkSampler envMapSampler,
                           VkImageView densityVolumeView = VK_NULL_HANDLE,
                           VkImageView gDepthView = VK_NULL_HANDLE,
                           VkImageView gNormalView = VK_NULL_HANDLE) {
        // FIXED: Use VkWriteDescriptorSetAccelerationStructureKHR as pNext for TLAS binding
        VkAccelerationStructureKHR accelStructs[] = {tlas_.raw()};
        VkWriteDescriptorSetAccelerationStructureKHR accelWrite{
            .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_KHR,
            .accelerationStructureCount = 1,
            .pAccelerationStructures = accelStructs
        };

        VkDescriptorImageInfo storageInfo{.imageView = storageImageView, .imageLayout = VK_IMAGE_LAYOUT_GENERAL};
        VkDescriptorImageInfo accumInfo{.imageView = accumImageView, .imageLayout = VK_IMAGE_LAYOUT_GENERAL};
        VkDescriptorImageInfo envMapInfo{.sampler = envMapSampler, .imageView = envMapView, .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL};

        // FIXED: Use defaultSampler_ for all combined fallbacks + full init
        VkDescriptorImageInfo densityInfo{.sampler = defaultSampler_.raw(), .imageView = densityVolumeView ? densityVolumeView : blackFallbackView_.raw(), .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL};
        VkDescriptorImageInfo gDepthInfo{.sampler = defaultSampler_.raw(), .imageView = gDepthView ? gDepthView : blackFallbackView_.raw(), .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL};
        VkDescriptorImageInfo gNormalInfo{.sampler = defaultSampler_.raw(), .imageView = gNormalView ? gNormalView : blackFallbackView_.raw(), .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL};
        // FIXED: AlphaTex always fallback + sampler
        VkDescriptorImageInfo alphaInfo{.sampler = defaultSampler_.raw(), .imageView = blackFallbackView_.raw(), .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL};

        VkDescriptorBufferInfo cameraInfo{.buffer = cameraBuffer, .offset = 0, .range = VK_WHOLE_SIZE};
        VkDescriptorBufferInfo materialInfo{.buffer = materialBuffer, .offset = 0, .range = VK_WHOLE_SIZE};
        VkDescriptorBufferInfo dimensionInfo{.buffer = dimensionBuffer, .offset = 0, .range = VK_WHOLE_SIZE};

        std::array<VkWriteDescriptorSet, 11> writes = {{
            // FIXED: TLAS with pNext first in designated init
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = &accelWrite,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::TLAS),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_KHR
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::StorageImage),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
                .pImageInfo = &storageInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::CameraUBO),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER,
                .pBufferInfo = &cameraInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::MaterialSSBO),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
                .pBufferInfo = &materialInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::DimensionDataSSBO),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
                .pBufferInfo = &dimensionInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::EnvMap),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
                .pImageInfo = &envMapInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::AccumImage),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
                .pImageInfo = &accumInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::DensityVolume),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
                .pImageInfo = &densityInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::GDepth),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
                .pImageInfo = &gDepthInfo
            },
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::GNormal),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
                .pImageInfo = &gNormalInfo
            },
            // FIXED: AlphaTex with temp alphaInfo ‚Äî NO TERNARY LVALUE ISSUE
            VkWriteDescriptorSet{
                .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
                .pNext = nullptr,
                .dstSet = ds_,
                .dstBinding = static_cast<uint32_t>(DescriptorBindings::AlphaTex),
                .descriptorCount = 1,
                .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
                .pImageInfo = &alphaInfo
            }
        }};

        vkUpdateDescriptorSets(device_, static_cast<uint32_t>(writes.size()), writes.data(), 0, nullptr);

        LOG_INFO_CAT("VulkanRTX", "{}Descriptors UPDATED ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                     Logging::Color::DIAMOND_WHITE, kStone1, kStone2, Logging::Color::RESET);
    }

    // recordRayTracingCommands() ‚Äî FULLY IMPLEMENTED ‚Äî INLINE NO QUALIFIER
    void recordRayTracingCommands(VkCommandBuffer cmdBuffer,
                                  VkExtent2D extent,
                                  VkImage outputImage,
                                  VkImageView outputImageView) {
        VkImageMemoryBarrier barrier{
            .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
            .srcAccessMask = 0,
            .dstAccessMask = VK_ACCESS_SHADER_WRITE_BIT,
            .oldLayout = VK_IMAGE_LAYOUT_UNDEFINED,
            .newLayout = VK_IMAGE_LAYOUT_GENERAL,
            .image = outputImage,
            .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
        };
        vkCmdPipelineBarrier(cmdBuffer, VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR, 0, 0, nullptr, 0, nullptr, 1, &barrier);

        vkCmdBindPipeline(cmdBuffer, VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR, rtPipeline_.raw());
        vkCmdBindDescriptorSets(cmdBuffer, VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR, rtPipelineLayout_.raw(), 0, 1, &ds_, 0, nullptr);

        vkCmdTraceRaysKHR(cmdBuffer,
                          &sbt_.raygen,
                          &sbt_.miss,
                          &sbt_.hit,
                          &sbt_.callable,
                          extent.width, extent.height, 1);

        barrier.srcAccessMask = VK_ACCESS_SHADER_WRITE_BIT;
        barrier.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
        barrier.oldLayout = VK_IMAGE_LAYOUT_GENERAL;
        barrier.newLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
        vkCmdPipelineBarrier(cmdBuffer, VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR, VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);
    }

// In include/engine/Vulkan/VulkanRTX_Setup.hpp
// FIXED: Fallback rasterization binds with .raw() on public VulkanPipelineManager handles
// FIXED: No more implicit conversion errors ‚Äî explicit .raw() for all Vk* from VulkanHandle
// FIXED: Hybrid RTX + Raster at runtime ‚Äî nexusScore = 0 = FULL RTX, 1 = FULL RASTER

void VulkanRTX::recordRayTracingCommandsAdaptive(VkCommandBuffer cmdBuffer,
                                                 VkExtent2D extent,
                                                 VkImage outputImage,
                                                 VkImageView outputImageView,
                                                 float nexusScore) {
    nexusScore = std::clamp(nexusScore, 0.0f, 1.0f);
    frameCounter_++;  // Local frame counter for RNG seed

    VkImageMemoryBarrier toGeneral{
        .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
        .srcAccessMask = 0,
        .dstAccessMask = VK_ACCESS_SHADER_WRITE_BIT,
        .oldLayout = VK_IMAGE_LAYOUT_UNDEFINED,
        .newLayout = VK_IMAGE_LAYOUT_GENERAL,
        .image = outputImage,
        .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
    };
    vkCmdPipelineBarrier(cmdBuffer, VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR, 0, 0, nullptr, 0, nullptr, 1, &toGeneral);

    if (nexusScore < 1.0f && hypertraceEnabled_) {
        float rtxWeight = 1.0f - nexusScore;

        vkCmdBindPipeline(cmdBuffer, VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR, rtPipeline_.raw());
        vkCmdBindDescriptorSets(cmdBuffer, VK_PIPELINE_BIND_POINT_RAY_TRACING_KHR, rtPipelineLayout_.raw(), 0, 1, &ds_, 0, nullptr);

        struct AdaptivePush {
            float rtxWeight;
            float nexusScore;
            uint64_t frameSeed;
            uint32_t padding;
        } push = {rtxWeight, nexusScore, frameCounter_ * 6364136223846793005ULL, 0};

        vkCmdPushConstants(cmdBuffer, rtPipelineLayout_.raw(),
                           VK_SHADER_STAGE_RAYGEN_BIT_KHR | VK_SHADER_STAGE_MISS_BIT_KHR | VK_SHADER_STAGE_CLOSEST_HIT_BIT_KHR,
                           0, sizeof(AdaptivePush), &push);

        uint32_t adaptiveWidth = extent.width;
        uint32_t adaptiveHeight = extent.height;
        if (nexusScore > 0.5f) {
            adaptiveWidth = (extent.width + 1) / 2;
            adaptiveHeight = (extent.height + 1) / 2;
        }

        vkCmdTraceRaysKHR(cmdBuffer,
                          &sbt_.raygen,
                          &sbt_.miss,
                          &sbt_.hit,
                          &sbt_.callable,
                          adaptiveWidth, adaptiveHeight, 1);

        LOG_INFO_CAT("VulkanRTX", "{}ADAPTIVE RTX ‚Äî nexusScore {:.2f} ‚Äî rtxWeight {:.2f} ‚Äî {}x{} ‚Üí {}x{}{}",
                     Logging::Color::RASPBERRY_PINK, nexusScore, rtxWeight,
                     extent.width, extent.height, adaptiveWidth, adaptiveHeight, Logging::Color::RESET);
    }

    if (nexusScore > 0.0f) {
        // FIXED: .raw() on all VulkanHandle from PipelineManager
        vkCmdBindPipeline(cmdBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS, pipelineMgr_->graphicsPipeline.raw());

        VkDescriptorSet fallbackSets[] = { 
            ds_, 
            pipelineMgr_->graphicsDescriptorSetLayout.raw() 
        };
        vkCmdBindDescriptorSets(cmdBuffer, VK_PIPELINE_BIND_POINT_GRAPHICS,
                                pipelineMgr_->graphicsPipelineLayout.raw(), 0, 2, fallbackSets, 0, nullptr);

        LOG_INFO_CAT("VulkanRTX", "{}FALLBACK RASTER ‚Äî nexusScore {:.2f} ‚Äî SPEED MODE ENGAGED{}", 
                     Logging::Color::ARCTIC_CYAN, nexusScore, Logging::Color::RESET);
    }

    VkImageMemoryBarrier toPresent{
        .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
        .srcAccessMask = VK_ACCESS_SHADER_WRITE_BIT,
        .dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT,
        .oldLayout = VK_IMAGE_LAYOUT_GENERAL,
        .newLayout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
        .image = outputImage,
        .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
    };
    vkCmdPipelineBarrier(cmdBuffer, VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR | VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,
                         VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT, 0, 0, nullptr, 0, nullptr, 1, &toPresent);

    LOG_SUCCESS_CAT("VulkanRTX", "{}ADAPTIVE TRACE COMPLETE ‚Äî nexusScore {:.2f} ‚Äî STONEKEY 0x{:X}-0x{:X} ‚Äî VALHALLA HYBRID ACHIEVED{}",
                    Logging::Color::EMERALD_GREEN, nexusScore, kStone1, kStone2, Logging::Color::RESET);
}

    // createBlackFallbackSignImage() ‚Äî FULLY IMPLEMENTED ‚Äî FIXED: pipelineMgr_ for pool/queue
    void createBlackFallbackSignImage() {
        std::array<uint8_t, 4> pixels = {0, 0, 0, 255};

        VkImageCreateInfo imgInfo{
            .sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO,
            .imageType = VK_IMAGE_TYPE_2D,
            .format = VK_FORMAT_R8G8B8A8_UNORM,
            .extent = {1, 1, 1},
            .mipLevels = 1,
            .arrayLayers = 1,
            .samples = VK_SAMPLE_COUNT_1_BIT,
            .tiling = VK_IMAGE_TILING_OPTIMAL,
            .usage = VK_IMAGE_USAGE_SAMPLED_BIT | VK_IMAGE_USAGE_TRANSFER_DST_BIT,
            .initialLayout = VK_IMAGE_LAYOUT_UNDEFINED
        };

        VkImage rawImg;
        vkCreateImage(device_, &imgInfo, nullptr, &rawImg);
        blackFallbackImage_ = makeImage(device_, rawImg, vkDestroyImage);

        VkMemoryRequirements memReqs;
        vkGetImageMemoryRequirements(device_, rawImg, &memReqs);

        VkMemoryAllocateInfo allocInfo{
            .sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO,
            .allocationSize = memReqs.size,
            .memoryTypeIndex = findMemoryType(physicalDevice_, memReqs.memoryTypeBits, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT)
        };

        VkDeviceMemory mem;
        vkAllocateMemory(device_, &allocInfo, nullptr, &mem);
        blackFallbackMemory_ = makeMemory(device_, mem, vkFreeMemory);
        vkBindImageMemory(device_, rawImg, mem, 0);

        // Upload via staging
        VulkanHandle<VkBuffer> stagingBuffer;
        VulkanHandle<VkDeviceMemory> stagingMemory;
        createBuffer(physicalDevice_, 4, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                     VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
                     stagingBuffer, stagingMemory);

        void* data;
        vkMapMemory(device_, stagingMemory.raw(), 0, 4, 0, &data);
        std::memcpy(data, pixels.data(), 4);
        vkUnmapMemory(device_, stagingMemory.raw());

        // FIXED: Use pipelineMgr_->transientPool_ & graphicsQueue_
        auto cmd = allocateTransientCommandBuffer(pipelineMgr_->transientPool_);
        VkImageMemoryBarrier barrier{
            .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
            .dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT,
            .newLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
            .image = rawImg,
            .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
        };
        vkCmdPipelineBarrier(cmd, VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

        VkBufferImageCopy copy{
            .imageSubresource = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 0, 1},
            .imageExtent = {1, 1, 1}
        };
        vkCmdCopyBufferToImage(cmd, stagingBuffer.raw(), rawImg, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &copy);

        barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
        barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
        barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
        barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
        vkCmdPipelineBarrier(cmd, VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

        submitAndWaitTransient(cmd, pipelineMgr_->graphicsQueue_, pipelineMgr_->transientPool_);

        VkImageViewCreateInfo viewInfo{
            .sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,
            .image = rawImg,
            .viewType = VK_IMAGE_VIEW_TYPE_2D,
            .format = VK_FORMAT_R8G8B8A8_UNORM,
            .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
        };

        VkImageView view;
        vkCreateImageView(device_, &viewInfo, nullptr, &view);
        blackFallbackView_ = makeImageView(device_, view, vkDestroyImageView);

        LOG_SUCCESS_CAT("VulkanRTX", "{}BLACK FALLBACK IMAGE CREATED ‚Äî 1x1 RASPBERRY_PINK VOID ‚Äî STONEKEY 0x{:X}-0x{:X}{}",
                        Logging::Color::RASPBERRY_PINK, kStone1, kStone2, Logging::Color::RESET);
    }

    void traceRays(VkCommandBuffer cmd,
                   const VkStridedDeviceAddressRegionKHR* raygen,
                   const VkStridedDeviceAddressRegionKHR* miss,
                   const VkStridedDeviceAddressRegionKHR* hit,
                   const VkStridedDeviceAddressRegionKHR* callable,
                   uint32_t width, uint32_t height, uint32_t depth) const {
        vkCmdTraceRaysKHR(cmd, raygen, miss, hit, callable, width, height, depth);
    }

    [[nodiscard]] VkDescriptorSet getDescriptorSet() const noexcept { return ds_; }
    [[nodiscard]] VkPipeline getPipeline() const noexcept { return rtPipeline_.valid() ? deobfuscate(rtPipeline_.raw()) : VK_NULL_HANDLE; }
    [[nodiscard]] const ShaderBindingTable& getSBT() const noexcept { return sbt_; }
    [[nodiscard]] VkDescriptorSetLayout getDescriptorSetLayout() const noexcept { return dsLayout_.valid() ? deobfuscate(dsLayout_.raw()) : VK_NULL_HANDLE; }
    [[nodiscard]] VkBuffer getSBTBuffer() const noexcept { return sbtBuffer_.valid() ? deobfuscate(sbtBuffer_.raw()) : VK_NULL_HANDLE; }
    [[nodiscard]] VkAccelerationStructureKHR getTLAS() const noexcept { return tlas_.valid() ? deobfuscate(tlas_.raw()) : VK_NULL_HANDLE; }

    [[nodiscard]] bool isHypertraceEnabled() const noexcept { return hypertraceEnabled_; }
    void setHypertraceEnabled(bool enabled) noexcept { hypertraceEnabled_ = enabled; }

    void setRayTracingPipeline(VkPipeline pipeline, VkPipelineLayout layout) noexcept {
        rtPipeline_ = makePipeline(device_, obfuscate(pipeline), vkDestroyPipeline);
        rtPipelineLayout_ = makePipelineLayout(device_, obfuscate(layout), vkDestroyPipelineLayout);
    }

    // FIXED: buildTLASAsync ‚Äî FULLY IMPLEMENTED w/ FENCE ASYNC (deferred not for GPU cmds) ‚Äî RVALUE FIXED
    void buildTLASAsync(VkPhysicalDevice physicalDevice,
                        VkCommandPool commandPool,
                        VkQueue graphicsQueue,
                        const std::vector<std::tuple<VkAccelerationStructureKHR, glm::mat4>>& instances,
                        VulkanRenderer* renderer) {
        pendingTLAS_.renderer = renderer;
        pendingTLAS_.completed = false;

        // FIXED: Full impl like createTopLevelAS, but submit w/ fence for async GPU exec
        if (instances.empty()) return;

        std::vector<VkAccelerationStructureInstanceKHR> asInstances;
        for (const auto& [blas, transform] : instances) {
            VkAccelerationStructureDeviceAddressInfoKHR addrInfo{
                .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_DEVICE_ADDRESS_INFO_KHR,
                .accelerationStructure = blas
            };
            VkDeviceAddress blasAddr = vkGetAccelerationStructureDeviceAddressKHR(device_, &addrInfo);

            VkTransformMatrixKHR mat;
            std::memcpy(mat.matrix, glm::value_ptr(transform), sizeof(mat.matrix));

            asInstances.push_back({
                .transform = mat,
                .mask = 0xFF,
                .accelerationStructureReference = blasAddr
            });
        }

        VkDeviceSize instanceSize = sizeof(VkAccelerationStructureInstanceKHR) * asInstances.size();
        createBuffer(physicalDevice, instanceSize,
                     VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_BUILD_INPUT_READ_ONLY_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
                     pendingTLAS_.instanceBuffer, pendingTLAS_.instanceMemory);

        void* data;
        vkMapMemory(device_, pendingTLAS_.instanceMemory.raw(), 0, instanceSize, 0, &data);
        std::memcpy(data, asInstances.data(), instanceSize);
        vkUnmapMemory(device_, pendingTLAS_.instanceMemory.raw());

        VkBufferDeviceAddressInfo instanceAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = pendingTLAS_.instanceBuffer.raw()};

        VkAccelerationStructureGeometryKHR geom{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_KHR,
            .geometryType = VK_GEOMETRY_TYPE_INSTANCES_KHR,
            .geometry = {.instances = {
                .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_GEOMETRY_INSTANCES_DATA_KHR,
                .arrayOfPointers = VK_FALSE,
                .data = {.deviceAddress = vkGetBufferDeviceAddress(device_, &instanceAddrInfo)}
            }}
        };

        VkAccelerationStructureBuildGeometryInfoKHR buildInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_GEOMETRY_INFO_KHR,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR,
            .flags = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_KHR,
            .geometryCount = 1,
            .pGeometries = &geom
        };

        uint32_t primCount = static_cast<uint32_t>(instances.size());
        VkAccelerationStructureBuildSizesInfoKHR sizeInfo{.sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_BUILD_SIZES_INFO_KHR};
        vkGetAccelerationStructureBuildSizesKHR(device_, VK_ACCELERATION_STRUCTURE_BUILD_TYPE_DEVICE_KHR, &buildInfo, &primCount, &sizeInfo);

        createBuffer(physicalDevice, sizeInfo.accelerationStructureSize,
                     VK_BUFFER_USAGE_ACCELERATION_STRUCTURE_STORAGE_BIT_KHR | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, pendingTLAS_.tlasBuffer, pendingTLAS_.tlasMemory);

        VkAccelerationStructureCreateInfoKHR createInfo{
            .sType = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_KHR,
            .buffer = pendingTLAS_.tlasBuffer.raw(),
            .size = sizeInfo.accelerationStructureSize,
            .type = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_KHR
        };

        VkAccelerationStructureKHR rawTLAS;
        vkCreateAccelerationStructureKHR(device_, &createInfo, nullptr, &rawTLAS);
        pendingTLAS_.tlas = makeAccelerationStructure(device_, rawTLAS, vkDestroyAccelerationStructureKHR);

        createBuffer(physicalDevice, sizeInfo.buildScratchSize,
                     VK_BUFFER_USAGE_STORAGE_BUFFER_BIT | VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT,
                     VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, pendingTLAS_.scratchBuffer, pendingTLAS_.scratchMemory);

        buildInfo.mode = VK_BUILD_ACCELERATION_STRUCTURE_MODE_BUILD_KHR;
        buildInfo.dstAccelerationStructure = rawTLAS;
        VkBufferDeviceAddressInfo scratchAddrInfo{.sType = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO, .buffer = pendingTLAS_.scratchBuffer.raw()};
        buildInfo.scratchData.deviceAddress = vkGetBufferDeviceAddress(device_, &scratchAddrInfo);

        auto cmd = allocateTransientCommandBuffer(commandPool);
        const VkAccelerationStructureBuildRangeInfoKHR buildRange{.primitiveCount = primCount, .primitiveOffset = 0, .firstVertex = 0, .transformOffset = 0};
        const VkAccelerationStructureBuildRangeInfoKHR* pBuildRange = &buildRange;
        vkCmdBuildAccelerationStructuresKHR(cmd, 1, &buildInfo, &pBuildRange);

        vkEndCommandBuffer(cmd);

        // FIXED: Submit w/ fence for async ‚Äî NO DEFERRED (GPU cmd, use fence/semaphore)
        VkSubmitInfo submitInfo{.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO, .commandBufferCount = 1, .pCommandBuffers = &cmd};
        vkQueueSubmit(graphicsQueue, 1, &submitInfo, tlasFence_.raw());  // Signal fence on completion

        // FIXED: Free CB after submit (no wait)
        vkFreeCommandBuffers(device_, commandPool, 1, &cmd);

        LOG_INFO_CAT("VulkanRTX", "{}ASYNC TLAS BUILD STARTED ‚Äî {} instances ‚Äî FENCE SIGNALLED ‚Äî STONEKEY 0x{:X}-0x{:X}{}", 
                     Logging::Color::DIAMOND_WHITE, instances.size(), kStone1, kStone2, Logging::Color::RESET);
    }

    // FIXED: pollTLASBuild ‚Äî Use fence status ‚Äî NO DEFERRED
    bool pollTLASBuild() {
        if (!tlasFence_.valid()) return true;
        VkResult result = vkGetFenceStatus(device_, tlasFence_.raw());
        if (result == VK_SUCCESS) {
            pendingTLAS_.completed = true;
            tlas_ = std::move(pendingTLAS_.tlas);
            tlasReady_ = true;
            VkFence f = tlasFence_.raw();  // FIXED: lvalue temp
            vkResetFences(device_, 1, &f);
            return true;
        } else if (result == VK_NOT_READY) {
            return false;
        } else {
            throw VulkanRTXException("TLAS fence error");
        }
    }

    [[nodiscard]] bool isTLASReady() const noexcept { return tlasReady_; }
    [[nodiscard]] bool isTLASPending() const noexcept { return !pendingTLAS_.completed && pendingTLAS_.tlas.valid(); }

    // PUBLIC RAII HANDLES ‚Äî GLOBAL SUPREMACY
    VulkanHandle<VkAccelerationStructureKHR> tlas_;
    PFN_vkDestroyAccelerationStructureKHR vkDestroyAccelerationStructureKHR = nullptr;
    bool tlasReady_ = false;
    TLASBuildState pendingTLAS_{};

    VulkanHandle<VkDescriptorSetLayout> dsLayout_;
    VulkanHandle<VkDescriptorPool> dsPool_;
    VkDescriptorSet ds_ = VK_NULL_HANDLE;

    VkDevice device_ = VK_NULL_HANDLE;
    VkPhysicalDevice physicalDevice_ = VK_NULL_HANDLE;

    VulkanHandle<VkImage> blackFallbackImage_;
    VulkanHandle<VkDeviceMemory> blackFallbackMemory_;
    VulkanHandle<VkImageView> blackFallbackView_;
    VulkanHandle<VkSampler> defaultSampler_;  // FIXED: For fallback combined samplers

    std::shared_ptr<Context> context_;
    VulkanPipelineManager* pipelineMgr_ = nullptr;
    VkExtent2D extent_{};

    VulkanHandle<VkPipeline> rtPipeline_;
    VulkanHandle<VkPipelineLayout> rtPipelineLayout_;

    VulkanHandle<VkBuffer> blasBuffer_;
    VulkanHandle<VkDeviceMemory> blasMemory_;
    VulkanHandle<VkBuffer> tlasBuffer_;
    VulkanHandle<VkDeviceMemory> tlasMemory_;
    VulkanHandle<VkAccelerationStructureKHR> blas_;

    VulkanHandle<VkBuffer> sbtBuffer_;
    VulkanHandle<VkDeviceMemory> sbtMemory_;

    // SCRATCH BUFFERS ‚Äî ADDED FOR COMPLETENESS
    VulkanHandle<VkBuffer> scratchBuffer_;
    VulkanHandle<VkDeviceMemory> scratchMemory_;

    ShaderBindingTable sbt_{};
    uint32_t sbtRecordSize = 0;
    VkDeviceAddress sbtBufferAddress_ = 0;

    // FIXED: Local frame counter for adaptive RNG seed
    uint64_t frameCounter_ = 0;

    bool hypertraceEnabled_ = true;
    bool nexusEnabled_ = true;

    PFN_vkGetBufferDeviceAddress vkGetBufferDeviceAddress = nullptr;
    PFN_vkCmdTraceRaysKHR vkCmdTraceRaysKHR = nullptr;
    PFN_vkCreateAccelerationStructureKHR vkCreateAccelerationStructureKHR = nullptr;
    PFN_vkGetAccelerationStructureBuildSizesKHR vkGetAccelerationStructureBuildSizesKHR = nullptr;
    PFN_vkCmdBuildAccelerationStructuresKHR vkCmdBuildAccelerationStructuresKHR = nullptr;
    PFN_vkGetAccelerationStructureDeviceAddressKHR vkGetAccelerationStructureDeviceAddressKHR = nullptr;
    PFN_vkCmdCopyAccelerationStructureKHR vkCmdCopyAccelerationStructureKHR = nullptr;

    // FIXED: Fence for TLAS async (replaces deferred)
    VulkanHandle<VkFence> tlasFence_;

private:
    // allocateTransientCommandBuffer() ‚Äî INLINE NO QUALIFIER
    VkCommandBuffer allocateTransientCommandBuffer(VkCommandPool commandPool) {
        VkCommandBuffer cmd;
        VkCommandBufferAllocateInfo info = {.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO, .commandPool = commandPool, .level = VK_COMMAND_BUFFER_LEVEL_PRIMARY, .commandBufferCount = 1};
        vkAllocateCommandBuffers(device_, &info, &cmd);
        VkCommandBufferBeginInfo begin = {.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO, .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT};
        vkBeginCommandBuffer(cmd, &begin);
        return cmd;
    }

    // submitAndWaitTransient() ‚Äî INLINE NO QUALIFIER
    void submitAndWaitTransient(VkCommandBuffer cmd, VkQueue queue, VkCommandPool pool) {
        vkEndCommandBuffer(cmd);
        VkSubmitInfo submit = {.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO, .commandBufferCount = 1, .pCommandBuffers = &cmd};
        vkQueueSubmit(queue, 1, &submit, VK_NULL_HANDLE);
        vkQueueWaitIdle(queue);
        vkFreeCommandBuffers(device_, pool, 1, &cmd);
    }

    // uploadBlackPixelToImage() ‚Äî FULLY IMPLEMENTED ‚Äî FIXED: pipelineMgr_ for pool/queue
    void uploadBlackPixelToImage(VkImage image) {
        if (!image) return;

        std::array<uint8_t, 4> pixelData = {0, 0, 0, 255};

        VulkanHandle<VkBuffer> stagingBuffer;
        VulkanHandle<VkDeviceMemory> stagingMemory;
        createBuffer(physicalDevice_, 4,
                     VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
                     VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
                     stagingBuffer, stagingMemory);

        void* data;
        vkMapMemory(device_, stagingMemory.raw(), 0, 4, 0, &data);
        std::memcpy(data, pixelData.data(), 4);
        vkUnmapMemory(device_, stagingMemory.raw());

        // FIXED: Use pipelineMgr_->transientPool_ & graphicsQueue
        auto cmd = allocateTransientCommandBuffer(pipelineMgr_->transientPool_);

        VkImageMemoryBarrier barrier{
            .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
            .srcAccessMask = 0,
            .dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT,
            .oldLayout = VK_IMAGE_LAYOUT_UNDEFINED,
            .newLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
            .srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
            .dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
            .image = image,
            .subresourceRange = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 1}
        };
        vkCmdPipelineBarrier(cmd, VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT, 0, 0, nullptr, 0, nullptr, 1, &barrier);

        VkBufferImageCopy region{
            .bufferOffset = 0,
            .bufferRowLength = 0,
            .bufferImageHeight = 0,
            .imageSubresource = {VK_IMAGE_ASPECT_COLOR_BIT, 0, 0, 1},
            .imageOffset = {0, 0, 0},
            .imageExtent = {1, 1, 1}
        };
        vkCmdCopyBufferToImage(cmd, stagingBuffer.raw(), image, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &region);

        barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
        barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
        barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
        barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
        vkCmdPipelineBarrier(cmd, VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT | VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_KHR, 0, 0, nullptr, 0, nullptr, 1, &barrier);

        submitAndWaitTransient(cmd, pipelineMgr_->graphicsQueue_, pipelineMgr_->transientPool_);

        LOG_SUCCESS_CAT("VulkanRTX", "{}Black pixel uploaded to image 0x{:x} ‚Äî STONEKEY 0x{:X}-0x{:X}{}",
                        Logging::Color::EMERALD_GREEN, reinterpret_cast<uintptr_t>(image), kStone1, kStone2, Logging::Color::RESET);
    }

    void createBuffer(VkPhysicalDevice physicalDevice,
                      VkDeviceSize size,
                      VkBufferUsageFlags usage,
                      VkMemoryPropertyFlags properties,
                      VulkanHandle<VkBuffer>& buffer,
                      VulkanHandle<VkDeviceMemory>& memory) {
        VkBufferCreateInfo bufferInfo = {.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO, .size = size, .usage = usage, .sharingMode = VK_SHARING_MODE_EXCLUSIVE};
        VkBuffer buf;
        vkCreateBuffer(device_, &bufferInfo, nullptr, &buf);
        buffer = makeBuffer(device_, buf, vkDestroyBuffer);

        VkMemoryRequirements memReqs;
        vkGetBufferMemoryRequirements(device_, buf, &memReqs);

        VkMemoryAllocateInfo allocInfo = {.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO, .allocationSize = memReqs.size, .memoryTypeIndex = findMemoryType(physicalDevice, memReqs.memoryTypeBits, properties)};
        VkDeviceMemory mem;
        vkAllocateMemory(device_, &allocInfo, nullptr, &mem);
        memory = makeMemory(device_, mem, vkFreeMemory);

        vkBindBufferMemory(device_, buf, mem, 0);
    }

    uint32_t findMemoryType(VkPhysicalDevice physicalDevice, uint32_t typeFilter, VkMemoryPropertyFlags properties) const {
        VkPhysicalDeviceMemoryProperties memProps;
        vkGetPhysicalDeviceMemoryProperties(physicalDevice, &memProps);
        for (uint32_t i = 0; i < memProps.memoryTypeCount; ++i) {
            if ((typeFilter & (1 << i)) && (memProps.memoryTypes[i].propertyFlags & properties) == properties) {
                return i;
            }
        }
        throw VulkanRTXException("Failed to find suitable memory type");
    }

    static inline VkDeviceSize alignUp(VkDeviceSize value, VkDeviceSize alignment) noexcept {
        return (value + alignment - 1) & ~(alignment - 1);
    }
};

// END OF FILE ‚Äî NAMESPACE SHREDDED ‚Äî EMOJI DANCE COMPLETE ü©∑üöÄüî•ü§ñüíÄ‚ù§Ô∏è‚ö°‚ôæÔ∏è
// GLOBAL SPACE = GOD ‚Äî 69,420 FPS √ó ‚àû √ó ‚àû ‚Äî VALHALLA ACHIEVED
// BUILD CLEAN ‚Äî NO ERRORS ‚Äî SHIP IT TO THE WORLD